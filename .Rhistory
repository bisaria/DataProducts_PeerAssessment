library(swirl)  # Loads swirl
install.packages("swirl")  # Installs swirl
library(swirl)  # Loads swirl
swirl()  # Runs swirl
5+7
x<-5+7
x
y<-x-3
y
z<-c(1.1,9,3.14)
?c
z
c(z,555,z)
z*2+100
mySqrt<-sqrt(z-1)
mySqrt
myDiv<-z/mySqrt
myDiv
c(1,2,3,4) + c(0,10)
c(1,2,3,4)+c(0,10,100)
1:20
pi:10
15:1
?`:`
seq(1,20)
seq(0,10,by=0.5)
my_seq<-seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along = my_seq)
seq_along(my_seq)
rep(0, times=40)
rep(c(0,1,2), times=10)
rep(c(0,1,2), each = 10)
num_vect<-c(0.5,55,-10,6)
tf<-num_vect < 1
tf
num_vect >= 6
my_char<-c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name<-c(my_char, "Rupa")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(c(1:3),c("X", "Y", "Z"),sep = "")
paste(c(1,2,3),c("X", "Y", "Z"),sep = "")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x<-c(44, NA, 5, NA)
x * 3
y<-rnorm(1000)
z<-rep(NA, 1000)
myData<-sample(c(y,z),100)
myNA<-is.na(myData)
myNA
myData == NA
sum(myNA)
myData
0/0
Inf-Inf
x
x[1:10]
x[is.na(x)]
y<-x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x >0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect<-c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2<-c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect,vect2)
vect["bar"]
vect[c("foo", "bar")]
myVector<-1:20
myVector
dim(myVector)
length(myVector)
dim(myVector)<-c(4,5)
dim(myVector)
attributes(myVector)
myVector
class(myVector)
myMatrix<-myVector
?matrix
myMatrix2<-matrix(c(1:20), nrow=4, ncol=5)
identical(myMatrix, myMatrix2)
patients<-c("Bill","Gina","Kelly","Sean")
cbind(patients, myMatrix)
myData<-data.frame(patients, myMatrix)
myData
class(myData)
cnames<-c("patient", "age", "weight", "bp","rating", "test")
colnames(myData)<-cnames
myData
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "56b637a5baffac62cad ec314b112fd746cdb36f5c8456148cdd3b8713ba9")
myapp <- oauth_app("github", "ec314b112fd746cdb36f5c8456148cdd3b8713ba")
myapp <- oauth_app("github", "ec314b112fd746cdb36f5c8456148cdd3b8713ba")
myapp <- oauth_app("github",key="b3e5488632cfeae22e97", secret = "ec314b112fd746cdb36f5c8456148cdd3b8713ba")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httpuv)
install.packages("httpuv")
library(httpuv)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github",key="b3e5488632cfeae22e97", secret = "ec314b112fd746cdb36f5c8456148cdd3b8713ba")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
q()
source('C:/Users/Anuroop Bisaria/Desktop/Online Course/Data Science Specialisation/Data Cleaning/oauth_github.R')
source('C:/Users/Anuroop Bisaria/Desktop/Online Course/Data Science Specialisation/Data Cleaning/oauth_github.R')
source('C:/Users/Anuroop Bisaria/Desktop/Online Course/Data Science Specialisation/Data Cleaning/oauth_github.R')
auth("b3e5488632cfeae22e97","ec314b112fd746cdb36f5c8456148cdd3b8713ba")
source('C:/Users/Anuroop Bisaria/Desktop/Online Course/Data Science Specialisation/Data Cleaning/Peer Assessment/run_analysis.R')
load(url("http://www.openintro.org/stat/data/mlb11.RData"))
View(mlb11)
ggplot(mlb11, aes(x=run, y=homeruns)) +
geom_point(shape=1)      # Use hollow circles
library(ggplot2)
ggplot(mlb11, aes(x=run, y=homeruns)) +
geom_point(shape=1)      # Use hollow circles
ggplot(mlb11, aes(x=runs, y=homeruns)) +
geom_point(shape=1)      # Use hollow circles
ggplot(mlb11, aes(x=at_bats, y=runs)) +
geom_point(shape=1)      # Use hollow circles
cor(mlb11$runs, mlb11$at_bats)
plot_ss(x = mlb11$at_bats, y = mlb11$runs)
plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = TRUE)
plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = TRUE)
plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = TRUE)
plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = TRUE)
m1 <- lm(runs ~ at_bats, data = mlb11)
summary(m1)
m2 <- lm(homeruns ~ runs, data = mlb11)
summary(m2)
plot_ss(x = mlb11$homeruns, y = mlb11$runs, showSquares = TRUE)
plot(mlb11$runs ~ mlb11$at_bats)
abline(m1)
plot(m1$residuals ~ mlb11$at_bats)
abline(h = 0, lty = 3)
hist(m1$residuals)
qqnorm(m1$residuals)
qqline(m1$residuals)
m3 <- lm(hits ~ runs, data = mlb11)
summary(m3)
m4 <- lm(wins ~ runs, data = mlb11)
summary(m4)
m5 <- lm(bat_avg ~ runs, data = mlb11)
summary(m5)
m6 <- lm(new_onbase ~ runs, data = mlb11)
summary(m6)
m6 <- lm(new_slug ~ runs, data = mlb11)
summary(m6)
m6 <- lm(new_obs ~ runs, data = mlb11)
summary(m6)
ggplot(mlb11, aes(x=at_bats, y=runs)) +
geom_point(shape=1)
ggplot(mlb11, aes(x=at_bats, y=runs)) + geom_point(shape=1)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mu = 0.3
sum(w(x - mu))
sum(w * (x - mu))
mu = 0.0025
sum(w * (x - mu))
mu = 1.077
sum(w * (x - mu))
mu = 0.1471
sum(w * (x - mu))
sum(w * (x - mu) ** 2)
mu = 1.077
sum(w * (x - mu) ** 2)
mu = 0.0025
sum(w * (x - mu) ** 2)
mu = 0.3
sum(w * (x - mu) ** 2)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
plot(y~x)
slope = -0.04462
sum((y - slope * x)**2)
slope = 0.8263
sum((y - slope * x)**2)
slope = -1.713
sum((y - slope * x)**2)
slope = 0.59915
sum((y - slope * x)**2)
beta1 <- sum(y * x) / sum(x ^ 2)
beta1
data(mtcars)
head(mtcars)
coef(lm(mpg ~ wt, mtcars))[2]
plot(mpg ~ wt, mtcars)
abline(lm)
abline()
beta1 <- 0.5 *  2
beta1
x<-c(1,2,3,4,5)
y<-c(2,3,4,4,5)
z<-c(5,6,7,8,9)
lm(z~x*y)
summary(lm(z~x*y))
summary(lm(z~I(x*y)))
x1<-x*y
summary(lm(z~x1)
)
library(MASS)
library(ISLR)
install.packages("ISLR")
library(ISLR)
names(Boston)
?Boston
plot(mdev~lstat, Boston)
plot(medv~lstat, Boston)
fit1<-lm(medv~lstat, Boston)
fit1
summary(fit1)
abline(fit1, col= "red")
names(fit1)
confint(fit1)
predict(fit1, data.frame(lstat = c(5,10,15)), interval = "confidence")
fit1<-lm(medv~lstat+age, data=Boston)
summary(fit2)
fit2<-lm(medv~lstat+age, data=Boston)
summary(fit2)
fit3<-lm(medv~.,data=Boston)
summary(fit3)
par(mfrow=c(2,2))
plot(fit3)
fit4<-update(fit3,~.-age-indus)
summary(fit4)
fit5<-lm(medv~lstat*age, Boston)
summary(fit5)
fit6<-lm(medv~lstat+I(lstat^2), Boston)
summary(fit6)
attach(Boston)
par(mfrow = c(1,1))
plot(medv~lstat)
points(lstat, fitted(fit6), col="red", pch=20)
fit7<-lm(medv~ploy(lstat,4))
points(lstat, fitted(fit7), col="blue", pch=20)
fit7<-lm(medv~ploy(lstat,4))
fit7<-lm(medv~poly(lstat,4))
points(lstat, fitted(fit7), col="blue", pch=20)
fix(carseats)
fix(Carseats)
summary(Carseats)
names(arseats)
names(Carseats)
fit1<-lm(Sales~.+Income:Advertising+Age:Price, Carseats)
summary(fit1)
contrasts(Carseats$Shelveloc)
contrasts(Carseats$ShelveLoc)
regplot<-function(x,y){
fit=lm(y~x)
plot(x,y)
abline(fit,col="red")
}
attach(Carseats)
regplot(Price,Sales)
regplot<-function(x,y,...){
fit=lm(y~x)
plot(x,y,...)
abline(fit,col="red")
}
regplot(Price,Sales,xlab="Price",ylab="Sales",col="blue",pch=20)
names(Smarket)
summary(Smarket)
?Smarket
pairs(Smarket, col = Smarket$Direction)
glm.fit<-glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial)
summary(glm.fit)
glm.probs<-predict(glm.fit, type="response")
glm.probs[1:5]
gel.pred<-ifelse(glm.probs>0.5,"Up","Down")
glm.pred<-ifelse(glm.probs>0.5,"Up","Down")
attach(Smarket)
table(glm.pred, Direction)
mean(glm.pred == Direction)
train<-Year<2005
glm.fit<-glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial, subset = train)
glm.pred<-ifelse(glm.probs>0.5,"Up","Down")
glm.probs<-predict(glm.fit,newdata=Smarket[!train] type="response")
glm.probs<-predict(glm.fit,newdata=Smarket[!train,] type="response")
glm.probs<-predict(glm.fit,newdata=Smarket[!train,], type="response")
glm.pred<-ifelse(glm.probs>0.5,"Up","Down")
Direction.2005<-Smarket$Direction[!train]
table(glm.fit, Direction.2005)
table(glm.pred, Direction.2005)
glm.pred
mean(glm.pred == Direction.2005)
glm.fit<-glm(Direction~Lag1+Lag2, data = Smarket, family = binomial, subset = train)
glm.probs<-predict(glm.fit,newdata=Smarket[!train,], type="response")
glm.pred<-ifelse(glm.probs>0.5,"Up","Down")
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
summary(glm.fit)
setwd("C:/Users/ANUROO~1/AppData/Local/Temp")
songs = read.csv("songs.csv")
setwd("C:/Users/ANUROO~1/AppData/Local/Temp")
songs = read.csv("songs.csv")
setwd("D:/Online Course/Analytical Edge/Assignment/Unit 3 - Logistic Regression")
songs = read.csv("songs.csv")
str(songs)
subset(songs, songtitle="Michael Jackson")
nrow(subset(songs, songtitle="Michael Jackson"))
nrow(subset(songs, songtitle=="Michael Jackson"))
View(songs)
nrow(subset(songs, artistname=="Michael Jackson"))
MichaelJackson = subset(songs, artistname == "Michael Jackson")
nrow(subset(MichaelJackson)
)
nrow(MichaelJackson)
MichaelJackson
MichaelJackson[,c()]
MichaelJackson[,c(songtitle)]
MichaelJackson[,c("songtitle")]
MichaelJackson[,c("songtitle", "Top10")]
MichaelJackson[MichaelJackson$Top10==1,c("songtitle")]
songs$timesignature = as.factor(songs$timesignature)
levels(songs$timesignature)
table(songs$timesignature)
lobrary(caTools)
library(caTools)
SongsTrain = sample.split(songs$Top10, SplitRatio = 0.7)
SongsTrain = subset(songs, year <= 2009)
SongsTest = subset(songs, year == 2010)
nrow(SongsTrain)
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
SongsLog1 = glm(Top10 ~ ., data=SongsTrain, family=binomial)
source('~/.active-rstudio-document', echo=TRUE)
cor(songs$loudness, songs$energy)
SongsLog2 = glm(Top10 ~ . - loudness, data=SongsTrain, family=binomial)
summary()
summary(SongsLog2)
SongsLog3 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
summary(SongsLog3)
predictTest = predict(SongsLog3, newdata=SongsTest)
predictTest = predict(SongsLog3, newdata=SongsTest, type="response")
table(SongsTest$Top10, predictTest>0.45)
(309+18)/(309+18+41+5)
table(SongsTest$Top10, predictTest>=0.45)
table(SongsTest$Top10)
table(SongsTest$Top10)/nrow(SongsTest)
setwd("D:/Online Course/Analytical Edge/Assignment/Unit 3 - Logistic Regression")
framingham = read.csv("framingham.csv")
# Look at structure
str(framingham)
# Load the library caTools
library(caTools)
# Randomly split the data into training and testing sets
set.seed(1000)
split = sample.split(framingham$TenYearCHD, SplitRatio = 0.65)
# Split up the data using subset
train = subset(framingham, split==TRUE)
test = subset(framingham, split==FALSE)
# Logistic Regression Model
framinghamLog = glm(TenYearCHD ~ ., data = train, family=binomial)
summary(framinghamLog)
# Predictions on the test set
predictTest = predict(framinghamLog, type="response", newdata=test)
# Confusion matrix with threshold of 0.5
table(test$TenYearCHD, predictTest > 0.5)
# Accuracy
(1069+11)/(1069+6+187+11)
# Baseline accuracy
(1069+6)/(1069+6+187+11)
# Test set AUC
library(ROCR)
ROCRpred = prediction(predictTest, test$TenYearCHD)
as.numeric(performance(ROCRpred, "auc")@y.values)
cor(framingham)
framinghamLog1 = glm(TenYearCHD ~ age+male+cigsPerDay+totChol+sysBP+glucose, data = train, family=binomial)
framinghamLog1 = glm(TenYearCHD ~ age+male+cigsPerDay+totChol+sysBP+glucose, data = train, family=binomial)
summary(framinghamLog1)
predictTest = predict(framinghamLog1, type="response", newdata=test)
table(test$TenYearCHD, predictTest > 0.5)
(1112+11)/(1112+11+194+7)
ROCRpred = prediction(predictTest, test$TenYearCHD)
as.numeric(performance(ROCRpred, "auc")@y.values)
setwd("D:/Online Course/Analytical Edge/Assignment/Unit 3 - Logistic Regression")
songs = read.csv("songs.csv")
str(songs)
SongsTrain = subset(songs, year <= 2009)
SongsTest = subset(songs, year == 2010)
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
SongsLog1 = glm(Top10 ~ ., data=SongsTrain, family=binomial)
summary(SongsLog1)
SongsLog3 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
summary(SongsLog3)
predictTest = predict(SongsLog3, newdata=SongsTest, type="response")
table(SongsTest$Top10, predictTest>=0.45)
(309+18)/(309+18+41+5)
table(SongsTest$Top10)/nrow(SongsTest)
# We can compute the sensitivity to be
18/(18+41)
# and the specificity to be
309/(309+5)
# Model 3 has a very high specificity, meaning that it favors specificity over sensitivity.
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
mainPanel()
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
levels(songs$timesignature)
table(songs$timesignature)
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
framingham = read.csv("framingham.csv")
# Look at structure
str(framingham)
# Load the library caTools
library(caTools)
# Randomly split the data into training and testing sets
set.seed(1000)
split = sample.split(framingham$TenYearCHD, SplitRatio = 0.65)
# Split up the data using subset
train = subset(framingham, split==TRUE)
test = subset(framingham, split==FALSE)
# Logistic Regression Model
framinghamLog = glm(TenYearCHD ~ ., data = train, family=binomial)
summary(framinghamLog)
predictTest = predict(framinghamLog, type="response", newdata=test)
# Confusion matrix with threshold of 0.5
table(test$TenYearCHD, predictTest > 0.5)
# Accuracy
(1069+11)/(1069+6+187+11)
# Baseline accuracy
(1069+6)/(1069+6+187+11)
# Test set AUC
library(ROCR)
ROCRpred = prediction(predictTest, test$TenYearCHD)
as.numeric(performance(ROCRpred, "auc")@y.values)
framinghamLog1 = glm(TenYearCHD ~ male+age+currentSmoker+diabetes+sysBP+totChol, data = train, family=binomial)
summary(framinghamLog1)
framinghamLog2 = glm(TenYearCHD ~ male+age+currentSmoker+BPMeds+sysBP+totChol, data = train, family=binomial)
summary(framinghamLog2)
framinghamLog3 = glm(TenYearCHD ~ male+age+currentSmoker+BMI+sysBP+totChol, data = train, family=binomial)
summary(framinghamLog3)
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
shiny::runApp('D:/Online Course/Developing Data Products/Project/App_1')
var = c("male","age","currentSmoker","BPMeds","totChol","sysBP")
framingham = subset(framingham, names(framingham)%in%var)
framingham = read.csv("data/framingham.csv")
setwd("D:/Online Course/Developing Data Products/Project/App_1")
framingham = read.csv("data/framingham.csv")
var = c("male","age","currentSmoker","BPMeds","totChol","sysBP")
framingham_sub = subset(framingham, names(framingham)%in%var)
framingham_sub = framingham[, names(framingham)%in%var]
shiny::runApp()
shiny::runApp()
framingham = read.csv("data/framingham.csv")
var = c("male","age","currentSmoker","BPMeds","totChol","sysBP", "TenYearCHD")
framingham = framingham[, names(framingham)%in%var]
framingham$male = c(1,2)
framingham = read.csv("data/framingham.csv")
framingham$BPMeds = c(1,2)
framingham = read.csv("data/framingham.csv")
levels(framingham$BPMeds) = c(1,2)
framingham = read.csv("data/framingham.csv")
var = c("male","age","currentSmoker","BPMeds","totChol","sysBP", "TenYearCHD")
framingham = framingham[, names(framingham)%in%var]
framingham$male = as.factor(framingham$male)
levels(framingham$male) = c(2,1)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
